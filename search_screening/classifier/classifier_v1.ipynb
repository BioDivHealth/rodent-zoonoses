{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f20ccd6-ef00-4002-bfd6-7ecd64ed6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import litstudy as lst\n",
    "import nltk\n",
    "#import Lbl2Vec as vec\n",
    "import pandas as pd\n",
    "import numpy as np#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer#for word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785ccc88-4c12-4abe-b901-de568cfdc9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title               0\n",
       "Authors            22\n",
       "Abstract          107\n",
       "Published Year      1\n",
       "Accepted            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = pd.read_csv(\"captive_wild_animals.csv\")\n",
    "master = master[[\"Title\", \"Authors\", \"Abstract\", \"Published Year\", \"Accepted\"]]\n",
    "master.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ee218d-d03c-422a-a6ea-cb8449ddaa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title             0\n",
       "Authors           0\n",
       "Abstract          0\n",
       "Published Year    0\n",
       "Accepted          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = master.dropna(ignore_index=True)\n",
    "master.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9421751a-0762-4fee-87ce-0174d71aabf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Published Year</th>\n",
       "      <th>Accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Health, emerging infectious diseases and w...</td>\n",
       "      <td>Cunningham AA; Daszak P; Wood JLN</td>\n",
       "      <td>Infectious diseases affect people, domestic an...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19-Zoonosis or Emerging Infectious Disease?</td>\n",
       "      <td>Haider N; Rothman-Ostrow P; Osman AY; Arruda L...</td>\n",
       "      <td>The World Health Organization defines a zoonos...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The role of wildlife in emerging and re-emergi...</td>\n",
       "      <td>Bengis RG; Leighton FA; Fischer JR; Artois M; ...</td>\n",
       "      <td>There are huge numbers of wild animals distrib...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global hotspots and correlates of emerging zoo...</td>\n",
       "      <td>Allen T; Murray KA; Zambrana-Torrelio C; Morse...</td>\n",
       "      <td>Zoonoses originating from wildlife represent a...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brucellosis in humans--etiology, diagnostics, ...</td>\n",
       "      <td>Galińska EM; Zagórski J</td>\n",
       "      <td>Brucellosis in humans is a zoonosis of greatly...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>Occurrence of ten protozoan enteric pathogens ...</td>\n",
       "      <td>Menu, E.; Davoust, B.; Mediannikov, O.; Akiana...</td>\n",
       "      <td>Non-human primate populations act as potential...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>Molecular and serological detection of Toxopla...</td>\n",
       "      <td>Hsu ChinWei; Wang PaoJung; Huang PeiYun; Lien ...</td>\n",
       "      <td>Toxoplasmosis caused by Toxoplasma gondii affe...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>Sequence analysis of novel Staphylococcus aure...</td>\n",
       "      <td>Monecke, S.; Roberts, M. C.; Braun, S. D.; Die...</td>\n",
       "      <td>Staphylococcus aureus is a widespread and comm...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>Intestinal parasites in captive wild animals a...</td>\n",
       "      <td>Qiu HongYu; Yang HuiNing; Sun XiaoJing; Jin Ch...</td>\n",
       "      <td>Objective: In order to investigate the prevale...</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>Evidence of exposure to USUV and WNV in zoo an...</td>\n",
       "      <td>Constant, O.; Bollore, K.; Clé, M.; Barthelemy...</td>\n",
       "      <td>West Nile virus (WNV) and Usutu virus (USUV) a...</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5534 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     One Health, emerging infectious diseases and w...   \n",
       "1     COVID-19-Zoonosis or Emerging Infectious Disease?   \n",
       "2     The role of wildlife in emerging and re-emergi...   \n",
       "3     Global hotspots and correlates of emerging zoo...   \n",
       "4     Brucellosis in humans--etiology, diagnostics, ...   \n",
       "...                                                 ...   \n",
       "5529  Occurrence of ten protozoan enteric pathogens ...   \n",
       "5530  Molecular and serological detection of Toxopla...   \n",
       "5531  Sequence analysis of novel Staphylococcus aure...   \n",
       "5532  Intestinal parasites in captive wild animals a...   \n",
       "5533  Evidence of exposure to USUV and WNV in zoo an...   \n",
       "\n",
       "                                                Authors  \\\n",
       "0                     Cunningham AA; Daszak P; Wood JLN   \n",
       "1     Haider N; Rothman-Ostrow P; Osman AY; Arruda L...   \n",
       "2     Bengis RG; Leighton FA; Fischer JR; Artois M; ...   \n",
       "3     Allen T; Murray KA; Zambrana-Torrelio C; Morse...   \n",
       "4                               Galińska EM; Zagórski J   \n",
       "...                                                 ...   \n",
       "5529  Menu, E.; Davoust, B.; Mediannikov, O.; Akiana...   \n",
       "5530  Hsu ChinWei; Wang PaoJung; Huang PeiYun; Lien ...   \n",
       "5531  Monecke, S.; Roberts, M. C.; Braun, S. D.; Die...   \n",
       "5532  Qiu HongYu; Yang HuiNing; Sun XiaoJing; Jin Ch...   \n",
       "5533  Constant, O.; Bollore, K.; Clé, M.; Barthelemy...   \n",
       "\n",
       "                                               Abstract Published Year  \\\n",
       "0     Infectious diseases affect people, domestic an...           2017   \n",
       "1     The World Health Organization defines a zoonos...           2020   \n",
       "2     There are huge numbers of wild animals distrib...           2004   \n",
       "3     Zoonoses originating from wildlife represent a...           2017   \n",
       "4     Brucellosis in humans is a zoonosis of greatly...           2013   \n",
       "...                                                 ...            ...   \n",
       "5529  Non-human primate populations act as potential...           2021   \n",
       "5530  Toxoplasmosis caused by Toxoplasma gondii affe...           2022   \n",
       "5531  Staphylococcus aureus is a widespread and comm...           2022   \n",
       "5532  Objective: In order to investigate the prevale...           2022   \n",
       "5533  West Nile virus (WNV) and Usutu virus (USUV) a...           2020   \n",
       "\n",
       "      Accepted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "5529         1  \n",
       "5530         1  \n",
       "5531         1  \n",
       "5532         1  \n",
       "5533         1  \n",
       "\n",
       "[5534 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e39287cd-2c15-4b72-b695-bede29014b00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### remove stopwords and punctuation.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize as tokenize\n",
    "\n",
    "words = tokenize(master[\"abstract\"][1])\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "extra = {\",\", \".\", \"(\", \")\", \";\", \":\", \"=\", \"[0-9]\"}\n",
    "filtered_list = []\n",
    "for word in words:\n",
    "    if word.casefold() not in stop_words and word.casefold() not in extra:\n",
    "         filtered_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63702497-1c3a-4b1a-b305-546695cb5b82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmed = [stemmer.stem(word) for word in filtered_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c9ebca1-0e6f-4dec-add2-dc080bcfef1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "abstracts = master[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9131ad7-7248-4dc5-a3b8-1c5f9fab8d5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize as tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nlp_dict = {}\n",
    "all_words = []\n",
    "row = int(0)\n",
    "for abstract in abstracts:\n",
    "    words = tokenize(abstract)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    extra = {\",\", \".\", \"(\", \")\", \";\", \":\", \"=\"}\n",
    "    filtered_list = []\n",
    "    for word in words:\n",
    "        if word.casefold() not in stop_words and word.casefold() not in extra:\n",
    "             filtered_list.append(word)\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in filtered_list]\n",
    "    nlp_dict[row] = stemmed\n",
    "    all_words.append(stemmed)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99b74fa-f14a-48ed-a7d0-923584c5c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\harrg\\AppData\\Local\\Temp\\ipykernel_20876\\925071319.py:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN# Tokenize the sentence\n",
    "\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6585736-5893-4ab7-9574-d610019ff1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "\n",
    "master['abstract_clean'] = master['Abstract'].apply(lambda x: finalpreprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4009c74d-5b42-498a-8356-0de29437bef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       infectious disease affect people domestic anim...\n",
       "1       world health organization defines zoonosis inf...\n",
       "2       huge number wild animal distribute throughout ...\n",
       "3       zoonosis originate wildlife represent signific...\n",
       "4       brucellosis human zoonosis greatly varied clin...\n",
       "                              ...                        \n",
       "5529    non human primate population act potential res...\n",
       "5530    toxoplasmosis cause toxoplasma gondii affect c...\n",
       "5531    staphylococcus aureus widespread common opport...\n",
       "5532    objective order investigate prevalence intesti...\n",
       "5533    west nile virus wnv usutu virus usuv zoonotic ...\n",
       "Name: abstract_clean, Length: 5534, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master[\"abstract_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b79cfa4-4e70-44fb-964e-741fe115f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(master[\"abstract_clean\"],master['Accepted'],test_size=0.9, shuffle=True)#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "375c186e-b7cf-4f22-8c3a-7794ea45a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c59d61-0aa9-416f-93c4-451938c4334d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "master['abstract_clean_tok']=[nltk.word_tokenize(i) for i in master['abstract_clean']]\n",
    "model = Word2Vec(master['abstract_clean_tok'],min_count=1, vector_size=100)     \n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "modelw = MeanEmbeddingVectorizer(w2v)# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efa94c5e-0289-4910-8089-7d8907b7e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4724\n",
      "           1       0.05      1.00      0.10       257\n",
      "\n",
      "    accuracy                           0.05      4981\n",
      "   macro avg       0.03      0.50      0.05      4981\n",
      "weighted avg       0.00      0.05      0.01      4981\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0 4724]\n",
      " [   0  257]]\n",
      "AUC: 0.7965093388508717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harrg\\AppData\\Local\\anaconda3\\envs\\litsearch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harrg\\AppData\\Local\\anaconda3\\envs\\litsearch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harrg\\AppData\\Local\\anaconda3\\envs\\litsearch\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=0.1, penalty = 'l2', class_weight={0: 1., 1: 100.})\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  #Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525326db-593c-463f-8c4b-5631ad095acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litsearch",
   "language": "python",
   "name": "litsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
